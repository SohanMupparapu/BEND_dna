/var/spool/slurmd/job41670/slurm_script: line 8: activate: No such file or directory
Which device
0
Script used: /z/home/frma/projects/BEND/scripts/train_downstream.py
Config path /z/home/frma/projects/BEND/conf/supervised_tasks/enhancer_annotation/
Run experiment
output_dir /z/home/frma/projects/DNA-LM/test1/
device cuda
CNN(
  (onehot_embedding): OneHotEmbedding()
  (conv1): Sequential(
    (0): TransposeLayer()
    (1): Conv1d(64, 2, kernel_size=(3,), stride=(1,), padding=(1,))
    (2): TransposeLayer()
    (3): GELU(approximate=none)
  )
  (conv2): Sequential(
    (0): TransposeLayer()
    (1): Conv1d(2, 2, kernel_size=(3,), stride=(1,), padding=(1,))
    (2): TransposeLayer()
    (3): GELU(approximate=none)
  )
  (linear): Sequential(
    (0): Linear(in_features=2, out_features=2, bias=True)
  )
  (softmax): Softmax(dim=-1)
  (softplus): Softplus(beta=1, threshold=20)
  (sigmoid): Sigmoid()
)
Use cross_entropy loss function
Split of dataset: Splitting with indices from file
Training
No checkpoints found, starting from scratch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
batch
Error executing job with overrides: []
Traceback (most recent call last):
  File "/z/home/frma/projects/BEND/scripts/train_downstream.py", line 72, in <module>
    run_experiment()
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/utils.py", line 222, in run_and_report
    raise ex
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/z/home/frma/lib/software/miniconda3/envs/torch-p310/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/z/home/frma/projects/BEND/scripts/train_downstream.py", line 65, in run_experiment
    trainer.train(train_loader, val_loader, cfg.params.epochs, cfg.params.load_checkpoint)
  File "/nfs/home/frma/projects/BEND/bend/utils/task_trainer.py", line 219, in train
    val_loss, val_metric = self.validate(val_loader)
  File "/nfs/home/frma/projects/BEND/bend/utils/task_trainer.py", line 258, in validate
    for n, (data, target, validated) in enumerate(val_loader):
ValueError: not enough values to unpack (expected 3, got 2)
